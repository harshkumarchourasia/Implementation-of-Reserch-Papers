{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout2d\n",
    "from torch.optim import Adam, SGD\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from skimage.transform import rotate, AffineTransform, warp\n",
    "import skimage.io as io\n",
    "import ctypes\n",
    "from PIL import Image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.ndimage import rotate\n",
    "import torch.nn.functional as F\n",
    "from random import random\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "labels = np.load('brain_tumor_dataset/labels.npy')\n",
    "images = np.load('brain_tumor_dataset/images.npy')\n",
    "masks = np.load('brain_tumor_dataset/masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3064/3064 [00:13<00:00, 222.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# vector X and Y contains all the training images and labels of the augmentatied dataset\n",
    "img = []\n",
    "lab = []\n",
    "for itr in tqdm(range(len(labels))):\n",
    "    temp = []\n",
    "    temp.append(images[itr,:,:])\n",
    "    img.append(temp)\n",
    "    lab.append(labels[itr]-1)\n",
    "    \n",
    "    temp=[]\n",
    "    temp.append(rotate(images[itr,:,:],90))\n",
    "    img.append(temp)\n",
    "    lab.append(labels[itr]-1)\n",
    "        \n",
    "    temp=[]\n",
    "    temp.append(rotate(images[itr,:,:],270))\n",
    "    img.append(temp)\n",
    "    lab.append(labels[itr]-1)   \n",
    "    \n",
    "    temp = []\n",
    "    temp.append(cv2.rotate(images[itr,:,:], cv2.ROTATE_180))\n",
    "    img.append(temp)\n",
    "    lab.append(labels[itr]-1)\n",
    "    \n",
    "img = np.array(img)\n",
    "lab = np.array(lab)\n",
    "#img = img.resize((img.shape[0],1,128,128))\n",
    "\n",
    "lab = lab.astype(int)\n",
    "\n",
    "class TrainHelper(Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = img.shape[0]\n",
    "        self.img, self.lab = img.astype('float32'), lab.astype('float32')\n",
    "        self.img = torch.from_numpy(img)\n",
    "        self.lab = torch.from_numpy(lab)\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx], self.lab[idx]\n",
    "traindataset = TrainHelper()\n",
    "train_loader = DataLoader(dataset = traindataset, batch_size=32,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dataapoint in each class are  [2832, 5704, 3720]\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(img,lab, test_size = 0.3, shuffle = True)\n",
    "(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)\n",
    "v=[0,0,0]\n",
    "for i in lab:\n",
    "    v[i]+=1\n",
    "print(\"number of dataapoint in each class are \", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(int)\n",
    "val_y = val_y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These classes helps to load data and implement batch wise training\n",
    "class TrainHelper(Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = train_x.shape[0]\n",
    "        self.train_x, self.train_y = train_x.astype('float32'), train_y.astype('float32')\n",
    "        self.train_x = torch.from_numpy(train_x)\n",
    "        self.train_y = torch.from_numpy(train_y)\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, idx):\n",
    "        return self.train_x[idx], self.train_y[idx]\n",
    "class ValHelper(Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = val_x.shape[0]\n",
    "        self.val_x, self.val_y = val_x.astype('float32'), val_y.astype('float32')\n",
    "        self.val_x = torch.from_numpy(val_x)\n",
    "        self.val_y = torch.from_numpy(val_y)\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    def __getitem__(self, idx):\n",
    "        return self.val_x[idx], self.val_y[idx]\n",
    "traindataset = TrainHelper()\n",
    "valdataset = ValHelper()\n",
    "train_loader = DataLoader(dataset = traindataset, batch_size=32,shuffle=True,num_workers=0)\n",
    "val_loader = DataLoader(dataset = valdataset, batch_size=32,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net50(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net50, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(1, 64, kernel_size=10, stride=1, padding=0),\n",
    "            ReLU(inplace=True),\n",
    "            BatchNorm2d(64),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Conv2d(64, 128, kernel_size=3, stride=1, padding=2),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Dropout2d(0.10),\n",
    "            \n",
    "            Conv2d(128, 256, kernel_size=2, stride=1, padding=2),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),         \n",
    "            Dropout2d(0.20),\n",
    "            \n",
    "            Conv2d(256,12544, kernel_size=7, padding=0),   # This tenique is called fully connected layer using convulation layer.\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            Conv2d(12544, 4, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        return x\n",
    "class Net(Module):\n",
    "    def __init__(self, model50):\n",
    "        super(Net, self).__init__()\n",
    "        self.model50 = model50\n",
    "        self.cnn_layers2 = Sequential(\n",
    "            Conv2d(3, 32, kernel_size=2, stride=1, padding=2),\n",
    "            ReLU(inplace=True),\n",
    "            BatchNorm2d(32),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Conv2d(32, 64, kernel_size=3, stride=1, padding=2),\n",
    "            ReLU(inplace=True),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            Dropout2d(0.10),   \n",
    "            \n",
    "            Conv2d(64, 1024,kernel_size=4),\n",
    "            ReLU(inplace=True),\n",
    "            \n",
    "            Conv2d(1024,3,kernel_size=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model50(x)\n",
    "        x = x[:,1:4]\n",
    "        x = self.cnn_layers2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 10, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model50 = Net50()\n",
    "#model50.load_state_dict(torch.load('50x50VA98.76epoch94k.pth'))\n",
    "a,b = next(iter(train_loader))\n",
    "out50 = model50(a.float())\n",
    "out50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (model50): Net50(\n",
      "    (cnn_layers): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(10, 10), stride=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "      (5): ReLU(inplace=True)\n",
      "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (7): Dropout2d(p=0.1, inplace=False)\n",
      "      (8): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "      (9): ReLU(inplace=True)\n",
      "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (11): Dropout2d(p=0.2, inplace=False)\n",
      "      (12): Conv2d(256, 12544, kernel_size=(7, 7), stride=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(12544, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (cnn_layers2): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.1, inplace=False)\n",
      "    (8): Conv2d(64, 1024, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(1024, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net(model50)\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#Stochastic Gradient Descent is used\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "l=[0,2,4,8,12,14]\n",
    "for i in l:\n",
    "    model.model50.cnn_layers[i].weight.requires_grad = False\n",
    "    model.model50.cnn_layers[i].bias.requires_grad = False\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Net50: 1-1                             [-1, 4, 10, 10]           --\n",
      "|    └─Sequential: 2-1                   [-1, 4, 10, 10]           --\n",
      "|    |    └─Conv2d: 3-1                  [-1, 64, 119, 119]        (6,464)\n",
      "|    |    └─ReLU: 3-2                    [-1, 64, 119, 119]        --\n",
      "|    |    └─BatchNorm2d: 3-3             [-1, 64, 119, 119]        (128)\n",
      "|    |    └─MaxPool2d: 3-4               [-1, 64, 59, 59]          --\n",
      "|    |    └─Conv2d: 3-5                  [-1, 128, 61, 61]         (73,856)\n",
      "|    |    └─ReLU: 3-6                    [-1, 128, 61, 61]         --\n",
      "|    |    └─MaxPool2d: 3-7               [-1, 128, 30, 30]         --\n",
      "|    |    └─Dropout2d: 3-8               [-1, 128, 30, 30]         --\n",
      "|    |    └─Conv2d: 3-9                  [-1, 256, 33, 33]         (131,328)\n",
      "|    |    └─ReLU: 3-10                   [-1, 256, 33, 33]         --\n",
      "|    |    └─MaxPool2d: 3-11              [-1, 256, 16, 16]         --\n",
      "|    |    └─Dropout2d: 3-12              [-1, 256, 16, 16]         --\n",
      "|    |    └─Conv2d: 3-13                 [-1, 12544, 10, 10]       (157,364,480)\n",
      "|    |    └─ReLU: 3-14                   [-1, 12544, 10, 10]       --\n",
      "|    |    └─Conv2d: 3-15                 [-1, 4, 10, 10]           (50,180)\n",
      "├─Sequential: 1-2                        [-1, 3, 1, 1]             --\n",
      "|    └─Conv2d: 2-2                       [-1, 32, 13, 13]          416\n",
      "|    └─ReLU: 2-3                         [-1, 32, 13, 13]          --\n",
      "|    └─BatchNorm2d: 2-4                  [-1, 32, 13, 13]          64\n",
      "|    └─MaxPool2d: 2-5                    [-1, 32, 6, 6]            --\n",
      "|    └─Conv2d: 2-6                       [-1, 64, 8, 8]            18,496\n",
      "|    └─ReLU: 2-7                         [-1, 64, 8, 8]            --\n",
      "|    └─MaxPool2d: 2-8                    [-1, 64, 4, 4]            --\n",
      "|    └─Dropout2d: 2-9                    [-1, 64, 4, 4]            --\n",
      "|    └─Conv2d: 2-10                      [-1, 1024, 1, 1]          1,049,600\n",
      "|    └─ReLU: 2-11                        [-1, 1024, 1, 1]          --\n",
      "|    └─Conv2d: 2-12                      [-1, 3, 1, 1]             3,075\n",
      "==========================================================================================\n",
      "Total params: 158,698,087\n",
      "Trainable params: 1,071,651\n",
      "Non-trainable params: 157,626,436\n",
      "Total mult-adds (G): 16.57\n",
      "==========================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 29.28\n",
      "Params size (MB): 605.39\n",
      "Estimated Total Size (MB): 634.73\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.random.randn(1,1,128,128)\n",
    "arr=torch.from_numpy(arr).float()\n",
    "summary(model,(1,128,128))\n",
    "model(arr).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr1=0\n",
    "highest_validation_accuracy = 0\n",
    "def train(epoch,tb):\n",
    "    global highest_validation_accuracy\n",
    "    global ctr1\n",
    "    # ctr1 are used to count the epoch for the test and training mini-batches\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in train_loader:\n",
    "        data, target = batch\n",
    "        x_train, y_train = Variable(data), Variable(target)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            x_train = x_train.cuda()\n",
    "            y_train = y_train.cuda()\n",
    "        \n",
    "        output_train = model(x_train.float())\n",
    "        output_train = output_train.reshape(-1,3)\n",
    "        #print(output_train.shape,x_train.shape, y_train.shape)\n",
    "        loss_train = criterion(output_train, y_train)\n",
    "        train_loss.append(loss_train.item()) \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        ctr1+=1\n",
    "        \n",
    "        _, predicted = torch.max(output_train.data, 1)\n",
    "        total += y_train.size(0)\n",
    "        correct += (predicted == y_train).sum().item()    \n",
    "    tb.add_scalar(\"Training Loss\", loss_train.item(), ctr1)\n",
    "    tb.add_scalar(\"Training accuracy\", correct/total,ctr1)     \n",
    "    \n",
    "\n",
    "    print(\"Training Loss on loop\",ctr1,\" is \",  np.mean(train_loss))\n",
    "    print(\"Training accuracy on loop\",ctr1,\" is \", correct/total)\n",
    "    validation_loss = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in val_loader:\n",
    "        data, target = batch\n",
    "        x_val, y_val = Variable(data), Variable(target)\n",
    "        if torch.cuda.is_available():\n",
    "            x_val = x_val.cuda()\n",
    "            y_val = y_val.cuda()\n",
    "        output_val = model(x_val.float())\n",
    "        output_val =  output_val.reshape(-1,3)\n",
    "        loss_val = criterion(output_val, y_val)\n",
    "        validation_loss.append(loss_val.item())            \n",
    "        _, predicted = torch.max(output_val.data, 1)\n",
    "        total += y_val.size(0)\n",
    "        correct += (predicted == y_val).sum().item()\n",
    "    tb.add_scalar(\"Validation Loss\", np.mean(validation_loss), ctr1)\n",
    "    tb.add_scalar(\"Validation accuracy\", correct/total,ctr1)\n",
    "    print(\"Validation Loss on loop\",ctr1,\" is \",  np.mean(validation_loss))\n",
    "    print(\"Validation accuracy on loop\",ctr1,\" is \", correct/total)\n",
    "    if highest_validation_accuracy-0.005 < correct/total:\n",
    "            highest_validation_accuracy = correct/total\n",
    "            name = \"ValidationAccuracy\"+str(highest_validation_accuracy)+\"epoch\"+str(ctr1)+'.pth'\n",
    "            torch.save(model.state_dict(),name)\n",
    "    \n",
    "    scheduler.step(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss on loop 269  is  0.4051427106376474\n",
      "Training accuracy on loop 269  is  0.8506818976570696\n",
      "Validation Loss on loop 269  is  0.19030373890114868\n",
      "Validation accuracy on loop 269  is  0.9330976339407125\n",
      "Training Loss on loop 538  is  0.14559456559251233\n",
      "Training accuracy on loop 538  is  0.95267513696235\n",
      "Validation Loss on loop 538  is  0.1314434919020404\n",
      "Validation accuracy on loop 538  is  0.9575741093282567\n",
      "Training Loss on loop 807  is  0.1119421964795173\n",
      "Training accuracy on loop 807  is  0.9629327427439095\n",
      "Validation Loss on loop 807  is  0.11414434736513573\n",
      "Validation accuracy on loop 807  is  0.96491705194452\n",
      "Training Loss on loop 1076  is  0.09266814124185356\n",
      "Training accuracy on loop 1076  is  0.9701596922718265\n",
      "Validation Loss on loop 1076  is  0.1134188207919183\n",
      "Validation accuracy on loop 1076  is  0.9635572477563231\n",
      "Training Loss on loop 1345  is  0.08219173036301058\n",
      "Training accuracy on loop 1345  is  0.9727240937172165\n",
      "Validation Loss on loop 1345  is  0.08665365337029747\n",
      "Validation accuracy on loop 1345  is  0.9711721512102257\n",
      "Training Loss on loop 1614  is  0.07941614427226405\n",
      "Training accuracy on loop 1614  is  0.9755216225667327\n",
      "Validation Loss on loop 1614  is  0.09137454706689586\n",
      "Validation accuracy on loop 1614  is  0.9730758770737014\n",
      "Training Loss on loop 1883  is  0.07438138322852773\n",
      "Training accuracy on loop 1883  is  0.9765706958853013\n",
      "Validation Loss on loop 1883  is  0.08173945095875988\n",
      "Validation accuracy on loop 1883  is  0.9738917595866196\n",
      "Training Loss on loop 2152  is  0.08035205276925325\n",
      "Training accuracy on loop 2152  is  0.977036950693554\n",
      "Validation Loss on loop 2152  is  0.1007786127374224\n",
      "Validation accuracy on loop 2152  is  0.9692684253467501\n",
      "Training Loss on loop 2421  is  0.07382059070747671\n",
      "Training accuracy on loop 2421  is  0.9742394218440378\n",
      "Validation Loss on loop 2421  is  0.08058015172896178\n",
      "Validation accuracy on loop 2421  is  0.9763394071253739\n",
      "Training Loss on loop 2690  is  0.0665123960674917\n",
      "Training accuracy on loop 2690  is  0.9784357151183122\n",
      "Validation Loss on loop 2690  is  0.08261345035356024\n",
      "Validation accuracy on loop 2690  is  0.9741637204242589\n",
      "Training Loss on loop 2959  is  0.059818504769424304\n",
      "Training accuracy on loop 2959  is  0.9793682247348175\n",
      "Validation Loss on loop 2959  is  0.08469327649749492\n",
      "Validation accuracy on loop 2959  is  0.972803916236062\n",
      "Training Loss on loop 3228  is  0.05312329542256044\n",
      "Training accuracy on loop 3228  is  0.982282317286397\n",
      "Validation Loss on loop 3228  is  0.07786740250885486\n",
      "Validation accuracy on loop 3228  is  0.9738917595866196\n",
      "Training Loss on loop 3497  is  0.06386834517342893\n",
      "Training accuracy on loop 3497  is  0.9836810817111551\n",
      "Validation Loss on loop 3497  is  0.09219213126470213\n",
      "Validation accuracy on loop 3497  is  0.9725319553984226\n",
      "Training Loss on loop 3766  is  0.0695224432470528\n",
      "Training accuracy on loop 3766  is  0.97761976920387\n",
      "Validation Loss on loop 3766  is  0.07333637529417225\n",
      "Validation accuracy on loop 3766  is  0.9755235246124558\n",
      "Training Loss on loop 4035  is  0.05876030753536295\n",
      "Training accuracy on loop 4035  is  0.9826320083925866\n",
      "Validation Loss on loop 4035  is  0.08283302013802787\n",
      "Validation accuracy on loop 4035  is  0.9790590155017678\n",
      "Training Loss on loop 4304  is  0.06370894125486173\n",
      "Training accuracy on loop 4304  is  0.979018533628628\n",
      "Validation Loss on loop 4304  is  0.07000354722790096\n",
      "Validation accuracy on loop 4304  is  0.9744356812618983\n",
      "Training Loss on loop 4573  is  0.04610578744883431\n",
      "Training accuracy on loop 4573  is  0.9847301550297237\n",
      "Validation Loss on loop 4573  is  0.07807155094392922\n",
      "Validation accuracy on loop 4573  is  0.9752515637748165\n",
      "Training Loss on loop 4842  is  0.04470710085919577\n",
      "Training accuracy on loop 4842  is  0.9844970276255974\n",
      "Validation Loss on loop 4842  is  0.07579220392457817\n",
      "Validation accuracy on loop 4842  is  0.9752515637748165\n",
      "Training Loss on loop 5111  is  0.04391234259373858\n",
      "Training accuracy on loop 5111  is  0.984846718731787\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "tb = SummaryWriter(comment = 'final model for prediction')\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch,tb)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
